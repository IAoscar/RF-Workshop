{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Binary Classification - Predicting Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries:\n",
    "\n",
    "Pandas - Data Manipulation & Analysis\n",
    "\n",
    "Sklearn - Machine Learning\n",
    "\n",
    "Seaborn - Data Visualization\n",
    "\n",
    "Matplotlib - Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data set into dataframe labeled \"medicalData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicalData = pd.read_csv('breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our data look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets drop any duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicalData = medicalData.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop ID for proper analysis and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicalData = medicalData.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fix the diagnosis column from M (malignant) to 1 and B (benign) to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicalData['diagnosis'] = medicalData['diagnosis'].map({'M': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData['diagnosis'].unique())\n",
    "print(medicalData['diagnosis'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets do some Explorative Data Analysis on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually counting the proportion of target cases in the whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=[]\n",
    "for i in range(len(medicalData)):\n",
    "    if medicalData['diagnosis'][i] == 1:\n",
    "        count.append(1)\n",
    "    else:\n",
    "        count.append(0)\n",
    "\n",
    "print(sum(count)/len(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicalData.hist(figsize=(15, 15), bins=30, edgecolor='black')\n",
    "plt.suptitle(\"Histograms\")\n",
    "plt.show()\n",
    "num_cols = medicalData.select_dtypes(include=['number']).columns \n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    sns.histplot(medicalData[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets prepare our data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medicalData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the X and Y sets\n",
    "\n",
    "\n",
    "X is the rows and columns of the predictors\n",
    "\n",
    "Y is the rows and column of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = medicalData.iloc[:,1:31].values\n",
    "Y = medicalData.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train_test_split() for model cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2, stratify=Y, random_state=3141)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model using RandomForestClassifier() and the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_class = RandomForestClassifier()\n",
    "rf_class.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = pandas.DataFrame(['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst'])\n",
    "loss_reduction = pandas.DataFrame(rf_class.feature_importances_, columns = ['loss_reduction'])\n",
    "var_importance = pandas.concat([var_names, loss_reduction], axis = 1)\n",
    "var_importance = var_importance.sort_values('loss_reduction', axis = 0, ascending= False)\n",
    "print(var_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets generate some metrics to check the performance of this basic model. \n",
    "\n",
    "First we generate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = rf_class.predict(X_test)\n",
    "Y_test = pandas.DataFrame(Y_test, columns = ['Cancer'])\n",
    "Y_pred = pandas.DataFrame(Y_pred, columns = ['Prediction'])\n",
    "df = pandas.concat([Y_test, Y_pred], axis = 1)\n",
    "count = (df['Cancer'] == df['Prediction']).sum()\n",
    "print(count/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets produce a confusion matrix and visualize it using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot = True, \n",
    "            fmt=\"d\", \n",
    "            cmap=\"Blues\", \n",
    "            xticklabels=['Pred 0', 'Pred 1'], \n",
    "            yticklabels=['True 0', 'True 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets generate the entire set of metrics that can be used to evaluate and compare different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
